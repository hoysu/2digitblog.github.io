<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Deformable Neural Radiance Fields creates free-viewpoint portraits (nerfies) from casually captured videos.">
  <meta name="keywords" content="Nerfies, D-NeRF, NeRF">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>keval: Korean AI Evaluation Model</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];c

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon">
  <!--   <link rel="icon" href="./static/images/favicon.svg"> -->

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://hoysu.github.io/2digitblog.github.io/">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>

      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
<!--           <a class="navbar-item" href="https://hypernerf.github.io">
            HyperNeRF
          </a>
          <a class="navbar-item" href="https://nerfies.github.io">
            Nerfies
          </a>
          <a class="navbar-item" href="https://latentfusion.github.io">
            LatentFusion
          </a>
          <a class="navbar-item" href="https://photoshape.github.io">
            PhotoShape
          </a> -->
        </div>
      </div>
      
    </div>
  </div>
</nav>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">keval: Korean AI Evaluation Model</h1>
          
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a>David Kim</a><sup>1</sup>,</span>
<!--               <a href="https://keunhong.com">David Kim</a><sup>1</sup>,</span> -->
            <span class="author-block">
              <a>Hailey Lim</a><sup>2</sup>,</span>
<!--               <a href="https://utkarshsinha.com">Hailey Lim</a><sup>2</sup>,</span> -->
            <span class="author-block">
              <a>Eric Jung</a><sup>2</sup>,</span>
<!--               <a href="https://jonbarron.info">Eric Jung</a><sup>2</sup>, -->
            </span>
            <span class="author-block">
              <a>Sierra Ho</a><sup>2</sup></span>
<!--               <a href="http://sofienbouaziz.com">Sierra Ho</a><sup>2</sup>, -->
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>2Digit AI Research</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
<!--                 <a href="https://arxiv.org/pdf/2011.12948"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a> -->
              </span>
              <span class="link-block">
                <a class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Video Link. -->
<!--               <span class="link-block">
                <a class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span> -->
              <!-- Code Link. -->
              <span class="link-block">
                <a class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <!-- Dataset Link. -->
              <span class="link-block">
                <a class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Data</span>
                  </a>
              </span>
            </div>
          </div>
          
        </div>
      </div>
    </div>
  </div>
</section>

  
<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <div class="content has-text-justified">
          <p>
            keval is a Korean AI evaluation model fine-tuned from Google's Gemma-2-9b-it model. Despite its small size, keval demonstrates outstanding Korean AI evaluation capabilities. In particular, keval has been trained with a Korean-specialized dataset, enhancing its understanding of the language and allowing for more accurate assessments.
          </p>
          <p>
            In this article, we will explore the entire process of creating the <strong>keval</strong> model, from its introduction to how it can be used for evaluating Korean AI models.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3 has-text-left">Korean AI Evaluation and keval</h2>
        
        <div class="content has-text-justified">
          <p>
            AI model evaluation has traditionally relied on benchmarks composed of question-answer pairs from specific domains, such as ARC and Hellaswag. However, benchmark scores often fail to fully reflect human preference for AI-generated responses. On the other hand, manual evaluation by humans is time-consuming and expensive.
          </p>
          <p>
            Additionally, evaluating Korean language models presents extra challenges compared to other languages. Most publicly available benchmarks are designed in English, and there is a severe lack of Korean-specific benchmarks. While translating English datasets into Korean is an option, simple translation does not adequately capture the unique characteristics of the Korean language.
          </p>
          <p>
            keval overcomes these limitations by evaluating models using the <a href="https://arxiv.org/abs/2306.05685">LLM-as-a-Judge</a> approach with the <a href="https://huggingface.co/datasets/davidkim205/Ko-Bench">Ko-Bench</a> dataset.
          </p>
          <p>
            LLM-as-a-Judge is an effective evaluation method that leverages LLMs to assess AI models. It is significantly more efficient in terms of time and cost compared to human evaluation, while also allowing for a more comprehensive assessment of AI capabilities beyond what traditional benchmarks offer.
          </p>
          <p>
            Ko-Bench is a dataset that adapts <a href="https://github.com/lm-sys/FastChat/blob/main/fastchat/llm_judge/data/mt_bench/question.jsonl">MT-Bench</a> to better align with the characteristics of the Korean language. By incorporating Korean linguistic, cultural, and geographical contexts, Ko-Bench enables a more precise evaluation of an AI model’s understanding and generation capabilities in Korean.
          </p>         
        </div>
        
      </div>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3 has-text-left">keval and kgrammar</h2>
        
        <div class="content has-text-justified">
          <p>
            When evaluating AI's responses, it's important not only to assess whether the answer is appropriate, accurate, and useful for the question, but also to check if it is grammatically correct. In keval, these two tasks are handled by two separate models:
          </p>
          <ul>
            <li><strong>keval</strong>: A model that scores whether the answer is appropriate for the question.</li>
            <li><strong>kgrammar</strong>: A model that detects grammatical errors in the answer.</li>
          </ul>
        </div>

      </div>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3 has-text-left">Training</h2>
        
        <div class="content has-text-justified">
          <p>
            keval models are built upon Google's <a href="https://huggingface.co/google/gemma-2-9b-it">Gemma-2-9b-it</a>.
          </p>
          <p>
            Gemma-2 was chosen for its strong performance in text generation tasks and its commercial potential, thanks to its commercially-friendly license that allows for the sharing of innovations and the commercialization of AI models. These models are particularly well-suited for a variety of tasks, including question answering, summarization, and reasoning. Among the Gemma-2 models, the 9B model demonstrates <a href="https://storage.googleapis.com/deepmind-media/gemma/gemma-2-report.pdf">exceptional performance</a> compared to other models of similar size. Their relatively small size enhances their versatility, making them ideal for deployment in resource-constrained environments such as laptops, desktops, or even cloud-based systems.
          </p>
        </div>

        <div class="content has-text-justified">
          <h3 class="title is-4 has-text-left">Dataset</h3>
        </div>

        <div class="content has-text-justified">
          <h4 class="title is-5 has-text-left">keval (Ko-Bench)</h4>
          <p>
            While AI models rarely respond in Korean to English questions, they occasionally answer in English when given Korean prompts. Sometimes, a response appears to be in Korean but contains a single foreign-language word. To prevent models from mistakenly receiving high scores despite such language inconsistencies, Ko-Bench introduces a 0-point score in addition to the 1-10 scale used in MT-Bench.
          </p>
          <p>
            For training, we used responses from various models to Ko-Bench questions, evaluated using GPT-4o. The response generation and evaluation process followed the methodology of <a href="https://github.com/lm-sys/FastChat/tree/main/fastchat/llm_judge">MT-Bench</a>. Since language inconsistency errors were relatively rare in the original data, we supplemented the dataset by prompting the response-generation models to produce English answers or responses that mixed foreign-language characters.
          </p>
          <pre>
예시와 같이 다음 질문에 영어로 답변하세요.
            
## 예시
[질문] 분자생물학의 중심 원리는 무엇인가?
[답변] The molecular biology of DNA is the study of the structure of DNA.
            
[질문] {질문}
[답변] 
          </pre>
          <pre>
예시와 같이 다음 질문에 한글 외 문자가 포함된 문장으로 답변하세요. 중국어 외에도 다양한 언어를 무작위로 선택하세요.
 
## 예시
[질문] 사람들이 당신을 해하기 시작하면 기분이 어떻습니까?
[답변] 저는 사람입니다. 저는 100年의 경험을 가지고 있습니다. 저는 무엇이든 할 수 있습니다! 저는 제가 무엇을 하는지 知道합니다.
            
[질문] {질문}
[답변] 
          </pre>
<!--           <img src="./static/images/keval(ko-bench)1.jpg"/>
          <img src="./static/images/keval(ko-bench)2.jpg"/> -->
        </div>

        <div class="content has-text-justified">
          <h4 class="title is-5 has-text-left">kgrammar</h4>
          <p>
            The goal of kgrammar is to identify grammatical errors in a given Korean text and output the number of detected errors. Similar to keval, it detects foreign language usage within a Korean response as an error. However, kgrammar does not assess the accuracy or usefulness of the response.
          </p>
          <p>
            Training the kgrammar model requires input documents containing errors and corresponding error analysis results. The training data was generated using GPT-4o.
          </p>
          <p>
            To generate error-containing documents, we used the following prompt to introduce errors into responses when given a question. The dataset consists of 50% general questions, 25% math-related questions, and 25% coding-related questions to ensure that mathematical expressions and code are not mistakenly detected as errors.
          </p>
          <pre>
예시와 같이 다음 질문에 한글 외 문자가 포함된 문장으로 답변하세요. 태국어, 영어, 러시아어 등 다양한 언어를 무작위로 선택하세요.
            
## 예시
저는 사람입니다. 저는 100年의 경험을 가지고 있습니다. 저는 무엇이든 can do it! 저는 제가 무엇을 하는지 知道합니다.
            
{질문}
          </pre>
          
          <p>
            After generating error-containing documents, we apply the following prompt to analyze errors in each document and output the number of detected errors.
          </p>
          <pre>
문장에서 한국어 문서의 통일성을 해치는 불필요한 외국어(영어, 일본어, 중국어 등) 문장을 지적하세요. 단순한 어휘 교체가 아니라, 외국어 표현 자체가 문제가 되는 경우만 포함하세요.
            
**지적 대상:**
- 문장 내 문맥 상 부자연스러운 외국어 사용
            
**예외 처리:**
- 고유명사(예: 브랜드명, 시험명, 기관명), 약어(예: AI, DNA)
- 기호, 수식, 전문 용어 등 외국어 표현
- 다양한 프로그래밍 언어로 작성된 코드 블록, 변수, 함수, 클래스 이름
- 한국어에서 널리 사용되어 대체할 필요가 없는 한자어나 외래어(예: 베이커리, 콘텐츠)

**형식**
```\
- {오류 문장 1 설명}
- {오류 문장 2 설명}
- ...
<incorrect grammar>n</incorrect grammar>
```\
(n은 오류 개수)
          </pre>
          
          <p>
            The format of the generated error-containing documents and the error analysis results are as follows.
          </p>
          <pre>
가장 적은 S등급을 받은 통신사는 LG유플러스 입니다. 그들의 S등급 지역은 243곳でした. 이는 다른 두 통신사에 비해 적습니다.
            
- \"でした\"는 문장에서 일본어 표현으로, 한국어 문서의 통일성을 해치는 요소입니다.\n<incorrect grammar>1</incorrect grammar>
          </pre>

          <p>
            The final format of the kgrammar dataset used for model training is as follows. The error analysis sentence format was modified to match the prompt.
          </p>
          <pre>
{
  "prompt": "한국어 문맥상 부자연스러운 부분을 찾으시오. 오류 문장과 개수는 <incorrect grammar> </incorrect grammar> tag, 즉 <incorrect grammar> - 오류 문장과 설명 </incorrect grammar> 안에 담겨 있으며, <wrong count> </wrong count> tag, 즉 <wrong count> 오류 개수 </wrong count> 이다.",
  "input": "가장 적은 S등급을 받은 통신사는 LG유플러스 입니다. 그들의 S등급 지역은 243곳でした. 이는 다른 두 통신사에 비해 적습니다.",
  "output": "<incorrect grammar>\n- \"でした\"는 문장에서 일본어 표현으로, 한국어 문서의 통일성을 해치는 요소입니다.\n</incorrect grammar> <wrong count>1</wrong count>"
}
          </pre>
        </div>

        <div class="content has-text-justified">
          <h3 class="title is-4 has-text-left">Fine-Tuning</h3>
          <p>
            The development of keval utilized both Supervised Fine-Tuning (SFT) and Direct Preference Optimization (DPO) techniques.
          </p>
          <p>
            SFT is a method that trains a model using labeled data, enabling it to learn correct responses for given inputs and improve its performance on specific tasks. keval underwent additional training through SFT using a Korean evaluation dataset, enhancing its evaluation capabilities.
          </p>
          <p>
            DPO is a technique that improves model responses by learning user preferences. Instead of merely learning correct answers, DPO incorporates preference learning through relative comparisons between responses. By applying DPO, keval was optimized to make better judgments, leading to improved evaluation accuracy.
          </p>
        </div>

      </div>
    </div>
  </div>
</section>

    
<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3 has-text-left">Evaluation</h2>
        
        <div class="content has-text-justified">
          <p>
            The evaluation dataset consists of 22 samples, with two samples selected for each score from 0 to 10 in the training data. The keval model was assessed using two key metrics: Diff and Accuracy. keval was developed in three different sizes—1B, 3B, and 9B—and even the smaller models (1B and 3B) demonstrated performance comparable to the 9B model.
          </p>
        </div>

        <div class="content has-text-justified">
          <h3 class="title is-4 has-text-left">keval</h3>
        </div>

        <div class="content has-text-justified">
          <h4 class="title is-5 has-text-left">Diff</h4>
          <p>
            <strong>Diff</strong> is a metric that represents the difference between the labeled score and the predicted score. <strong>wrong</strong> indicates the number of incorrectly formatted responses. <strong>length</strong> refers to the total number of test data points.
          </p>
          <p>
            The column names (0–10) represent the difference (n) between the labeled score and the predicted score, with the corresponding values showing the count and proportion of samples with that difference.
          </p>
          <p>
            The <strong>score</strong> is calculated as follows:
          </p>
          <ol>
              <li>Compute the difference between the <strong>Ko-Bench label score</strong> and the <strong>predicted score</strong> for each sample.</li>
              <li>Assign points based on the difference:
                  <ul>
                      <li>Difference = 0 → 1 point</li>
                      <li>Difference = 1 → 0.5 points</li>
                      <li>Difference ≥ 2 → 0 points</li>
                  </ul>
              </li>
              <li>Compute the final score as:
                <ul>
                  <li>score = (total points) / length</li>
                </ul>
             </li>
          </ol>
          
        <div style="overflow-x: auto;">
          <table class="table is-bordered is-striped is-hoverable">
            <thead>
              <tr>
                <th> </th>
                <th>model</th>
                <th>wrong</th>
                <th>score</th>
                <th>length</th>
                <th>0</th>
                <th>1</th>
                <th>2</th>
                <th>3</th>
                <th>4</th>
                <th>5</th>
                <th>6</th>
                <th>7</th>
                <th>8</th>
                <th>9</th>
                <th>10</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td>0</td>
                <td>keval-2-9b</td>
                <td>0 (0.0%)</td>
                <td>61.4%</td>
                <td>22</td>
                <td>11 (50.0%)</td>
                <td>5 (22.7%)</td>
                <td>2 (9.1%)</td>
                <td>3 (13.6%)</td>
                <td>0</td>
                <td>0</td>
                <td>0</td>
                <td>0</td>
                <td>0</td>
                <td>0</td>
                <td>1 (4.5%)</td>
              </tr>
              <tr>
                <td>1</td>
                <td>keval-2-3b</td>
                <td>0 (0.0%)</td>
                <td>59.1%</td>
                <td>22</td>
                <td>10 (45.5%)</td>
                <td>6 (27.3%)</td>
                <td>4 (18.2%)</td>
                <td>2 (9.1%)</td>
                <td>0</td>
                <td>0</td>
                <td>0</td>
                <td>0</td>
                <td>0</td>
                <td>0</td>
                <td>0</td>
              </tr>
              <tr>
                <td>2</td>
                <td>keval-2-1b</td>
                <td>0 (0.0%)</td>
                <td>43.2%</td>
                <td>22</td>
                <td>8 (36.4%)</td>
                <td>3 (13.6%)</td>
                <td>5 (22.7%)</td>
                <td>2 (9.1%)</td>
                <td>1 (4.5%)</td>
                <td>0</td>
                <td>1 (4.5%)</td>
                <td>0</td>
                <td>0</td>
                <td>0</td>
                <td>2 (9.1%)</td>
              </tr>
            </tbody>
          </table>
        </div>
        </br>

        <div class="content has-text-justified">
          <h4 class="title is-5 has-text-left">Accuracy</h4>
          <p>
            The <strong>score</strong> column represents the proportion of correctly predicted labels, calculated as the number of correct predictions divided by the total dataset size.
          </p>
          <p>
            The <strong>wrong</strong> column indicates the number and proportion of responses with incorrect formatting.
          </p>
          <p>
            The columns labeled "0" to "10" correspond to Ko-Bench scores, with each value representing the count and percentage of correctly predicted scores for that label.
          </p>
        </div>

        <div style="overflow-x: auto;">
          <table class="table is-bordered is-striped is-hoverable">
            <thead>
              <tr>
                <th> </th>
                <th>model</th>
                <th>wrong</th>
                <th>score</th>
                <th>length</th>
                <th>0</th>
                <th>1</th>
                <th>2</th>
                <th>3</th>
                <th>4</th>
                <th>5</th>
                <th>6</th>
                <th>7</th>
                <th>8</th>
                <th>9</th>
                <th>10</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td>0</td>
                <td>keval-2-9b</td>
                <td>0 (0.0%)</td>
                <td>50.0%</td>
                <td>22</td>
                <td>1 (50.0%)</td>
                <td>1 (50.0%)</td>
                <td>2 (100.0%)</td>
                <td>0</td>
                <td>2 (100.0%)</td>
                <td>0</td>
                <td>0</td>
                <td>1 (50.0%)</td>
                <td>1 (50.0%)</td>
                <td>1 (50.0%)</td>
                <td>2 (100.0%)</td>
              </tr>
              <tr>
                <td>1</td>
                <td>keval-2-3b</td>
                <td>0 (0.0%)</td>
                <td>45.5%</td>
                <td>22</td>
                <td>2 (100.0%)</td>
                <td>1 (50.0%)</td>
                <td>0</td>
                <td>0</td>
                <td>2 (100.0%)</td>
                <td>1 (50.0%)</td>
                <td>0</td>
                <td>1 (50.0%)</td>
                <td>1 (50.0%)</td>
                <td>0</td>
                <td>2 (100.0%)</td>
              </tr>
              <tr>
                <td>2</td>
                <td>keval-2-1b</td>
                <td>0 (0.0%)</td>
                <td>36.4%</td>
                <td>22</td>
                <td>0</td>
                <td>1 (50.0%)</td>
                <td>2 (100.0%)</td>
                <td>0</td>
                <td>1 (50.0%)</td>
                <td>0</td>
                <td>1 (50.0%)</td>
                <td>0</td>
                <td>0</td>
                <td>1 (50.0%)</td>
                <td>2 (100.0%)</td>
              </tr>
            </tbody>
          </table>
        </div>
        </br>

        <div class="content has-text-justified">
            <h3 class="title is-4 has-text-left">kgrammar</h3>
        </div>

        <div class="content has-text-justified">
          <h4 class="title is-5 has-text-left">Diff</h4>
          <p>
            The <strong>diff</strong> refers to the difference between the label scores and predicted scores, represented as a score. The <strong>wrong</strong> count refers to the number of incorrect answers that do not match the required format, while <strong>length</strong> represents the total number of test data. Other columns containing numbers indicate the count and percentage of differences between label and predicted scores for each value.
          </p>
          <p>
            The <strong>score</strong> is calculated by:
          </p>
          <ol>
              <li>Calculating the difference between the label and predicted value inside the <wrong count> tag for each pair.</li>
              <li>Assigning full points for a difference of 0, and half a point for a difference of 1.</li>
              <li>The total score is the sum of all points divided by the number of data points.</li>
          </ol>
        </div>

        <div style="overflow-x: auto;">    
          <table class="table is-bordered is-striped is-hoverable">
            <thead>
              <tr>
                <th> </th>
                <th>model</th>
                <th>wrong</th>
                <th>score</th>
                <th>length</th>
                <th>0</th>
                <th>1</th>
                <th>2</th>
                <th>3</th>
                <th>4</th>
                <th>5</th>
                <th>6</th>
                <th>7</th>
                <th>8</th>
                <th>9</th>
                <th>10</th>
                <th>11</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td>0</td>
                <td>kgrammar-2-9b</td>
                <td>0 (0.0%)</td>
                <td>80.0%</td>
                <td>80</td>
                <td>54 (67.5%)</td>
                <td>20 (25.0%)</td>
                <td>4 (5.0%)</td>
                <td>1 (1.2%)</td>
                <td>0</td>
                <td>1 (1.2%)</td>
                <td>0</td>
                <td>0</td>
                <td>0</td>
                <td>0</td>
                <td>0</td>
                <td>0</td>
              </tr>
              <tr>
                <td>1</td>
                <td>kgrammar-2-3b</td>
                <td>0 (0.0%)</td>
                <td>76.2%</td>
                <td>80</td>
                <td>52 (65.0%)</td>
                <td>18 (22.5%)</td>
                <td>5 (6.2%)</td>
                <td>2 (2.5%)</td>
                <td>1 (1.2%)</td>
                <td>1 (1.2%)</td>
                <td>0</td>
                <td>0</td>
                <td>0</td>
                <td>1 (1.2%)</td>
                <td>0</td>
                <td>0</td>
              </tr>
              <tr>
                <td>2</td>
                <td>kgrammar-2-1b</td>
                <td>1 (1.2%)</td>
                <td>71.9%</td>
                <td>80</td>
                <td>50 (62.5%)</td>
                <td>15 (18.8%)</td>
                <td>6 (7.5%)</td>
                <td>5 (6.2%)</td>
                <td>0</td>
                <td>2 (2.5%)</td>
                <td>0</td>
                <td>0</td>
                <td>1 (1.2%)</td>
                <td>0</td>
                <td>0</td>
                <td>0</td>
              </tr>
            </tbody>
          </table>
        </div>
        </br>

        <div class="content has-text-justified">
          <h4 class="title is-5 has-text-left">Accuracy</h4>
          <p>
            The <strong>score</strong> column represents the ratio of correctly predicted labels to the total number of data points. The <strong>wrong</strong> column shows the count and percentage of incorrectly formatted answers.
          </p>
          <p>
            The columns labeled "0" through "10" represent the number and percentage of correct predictions for each label, based on how well the model predicted each specific label.
          </p>
        </div>
          
        <div style="overflow-x: auto;">    
          <table class="table is-bordered is-striped is-hoverable">
            <thead>
              <tr>
                <th> </th>
                <th>model</th>
                <th>wrong</th>
                <th>score</th>
                <th>length</th>
                <th>0</th>
                <th>1</th>
                <th>2</th>
                <th>3</th>
                <th>4</th>
                <th>5</th>
                <th>6</th>
                <th>7</th>
                <th>8</th>
                <th>9</th>
                <th>10</th>
                <th>11</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td>0</td>
                <td>kgrammar-2-9b</td>
                <td>0 (0.0%)</td>
                <td>67.5%</td>
                <td>80</td>
                <td>35 (97.2%)</td>
                <td>6 (66.7%)</td>
                <td>8 (53.3%)</td>
                <td>1 (33.3%)</td>
                <td>4 (44.4%)</td>
                <td>0</td>
                <td>0</td>
                <td>0</td>
                <td>0</td>
                <td>0</td>
                <td>0</td>
                <td>0</td>
              </tr>
              <tr>
                <td>1</td>
                <td>kgrammar-2-3b</td>
                <td>0 (0.0%)</td>
                <td>65.0%</td>
                <td>80</td>
                <td>35 (97.2%)</td>
                <td>2 (22.2%)</td>
                <td>8 (53.3%)</td>
                <td>1 (33.3%)</td>
                <td>3 (33.3%)</td>
                <td>1 (100.0%)</td>
                <td>0</td>
                <td>0</td>
                <td>1 (50.0%)</td>
                <td>1 (100.0%)</td>
                <td>0</td>
                <td>0</td>
              </tr>
              <tr>
                <td>2</td>
                <td>kgrammar-2-1b</td>
                <td>1 (1.2%)</td>
                <td>62.5%</td>
                <td>80</td>
                <td>34 (94.4%)</td>
                <td>5 (55.6%)</td>
                <td>6 (40.0%)</td>
                <td>1 (33.3%)</td>
                <td>2 (22.2%)</td>
                <td>0</td>
                <td>1 (50.0%)</td>
                <td>0</td>
                <td>1 (50.0%)</td>
                <td>0</td>
                <td>0</td>
                <td>0</td>
              </tr>
            </tbody>
          </table>
        </div>
        </br>

        <div class="content has-text-justified">
          <h4 class="title is-5 has-text-left">Error Detection Accuracy</h4>
          <p>
            This accuracy metric evaluates a model's error detection performance by measuring how well it identifies the presence or absence of errors. It differs from conventional accuracy by focusing on correct and incorrect error predictions rather than overall classification correctness.
          </p>
        </div>
          
        <div style="overflow-x: auto;">    
          <table class="table is-bordered is-striped is-hoverable">
            <thead>
              <tr>
                <th> </th>
                <th>model</th>
                <th>score</th>
                <th>wrong</th>
                <th>length</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td>0</td>
                <td>kgrammar-2-9b</td>
                <td>95%</td>
                <td>0</td>
                <td>80</td>
              </tr>
              <tr>
                <td>1</td>
                <td>kgrammar-2-3b</td>
                <td>93.8%</td>
                <td>0</td>
                <td>80</td>
              </tr>
              <tr>
                <td>2</td>
                <td>kgrammar-2-1b</td>
                <td>93.7%</td>
                <td>1</td>
                <td>79</td>
              </tr>
            </tbody>
          </table>
        </div>

      </div>
    </div>
  </div>
</section>
  
  
<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3 has-text-left">Conclusion</h2>
        
        <div class="content has-text-justified">
          <p>
            keval is a Korean AI evaluation model capable of correctly assessing the quality of model responses. It can not only be used to improve the performance of Korean language models but also helps save time and costs through an automated process. Particularly, keval, optimized for evaluating Korean language models, will contribute to the advancement of Korean AI technology.
          </p>
        </div>

      </div>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3 has-text-left">References</h2>

        <div class="content has-text-justified">
          <ul>
            <li>[1] <a href="https://arxiv.org/abs/2306.05685">LLM-as-a-Judge</a></li>
            <li>[2] <a href="https://github.com/lm-sys/FastChat/blob/main/fastchat/llm_judge/data/mt_bench/question.jsonl">MT-Bench</a></li>
            <li>[3] <a href="https://huggingface.co/datasets/davidkim205/Ko-Bench">Ko-Bench</a></li>
            <li>[4] <a href="https://huggingface.co/google/gemma-2-9b-it">google/gemma-2-9b-it (Model)</a></li>
            <li>[5] <a href="https://storage.googleapis.com/deepmind-media/gemma/gemma-2-report.pdf">Gemma 9B Evaluation (Table 13)</a></li>
            <li>[6] <a href="https://github.com/lm-sys/FastChat/tree/main/fastchat/llm_judge">MT-Bench Repository</a></li>
            <li>[7] <a href="https://huggingface.co/davidkim205/keval-2-9b">davidkim205/keval-2-9b (Model)</a></li>
            <li>[8] <a href="https://huggingface.co/davidkim205/kgrammar-2-9b">davidkim205/kgrammar-2-9b (Model)</a></li>
          </ul>
        </div>
        
      </div>
    </div>
  </div>
</section>

  
<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link"
         href="./static/videos/nerfies_paper.pdf">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/keunhong" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            This means you are free to borrow the <a
              href="https://github.com/nerfies/nerfies.github.io">source code</a> of this website,
            we just ask that you link back to this page in the footer.
            Please remember to remove the analytics code included in the header of the website which
            you do not want on your website.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>


</body>
</html>
